# CS229 Final Project
This project extends the CATO (cost-aware traffic analysis optimization) line of work by testing whether newer deep learning architectures can be effective alternatives to the more traditional ML models originally used for network traffic analysis. Using publicly available packet captures from 30 IoT devices (23.8M packets over 20 days), we build a flow-level dataset of 255,030 bidirectional connections and extract 17 packet/flow statistics (e.g., bytes, packets, inter-arrival time, TTL, RTT) using the Rust-based Retina framework. We first reproduce a Random Forest baseline in Rust (SmartCore) to validate the end-to-end data and evaluation pipeline, achieving 95.7% accuracy and 0.9706 weighted F1 on a held-out test set. We then benchmark three contemporary model families—an iTransformer time-series transformer, LSTMs, and a GraphSAGE graph neural network—reporting accuracy plus macro/weighted F1 under extreme class imbalance. The best iTransformer configuration reaches 0.9521 weighted F1 (macro F1 0.4627), GraphSAGE achieves ~93% accuracy with ~0.95 weighted F1 and improves macro F1 with increased depth (0.50 → 0.53), and LSTM experiments reach ~74% accuracy (F1 ≈ 0.73 in the best setting). Overall, results show that high weighted F1 can mask poor minority-class performance, and improving macro-F1 on rare devices remains challenging. A key direction for future work is integrating these models into the full CATO pipeline and evaluating end-to-end cost (feature extraction + inference latency), not just predictive metrics.

My contribution: I led the Graph Neural Network (GNN) component of the project. I implemented the full GraphSAGE pipeline end-to-end: parsing and normalizing the flow dataset, constructing a graph where each flow is a node and edges connect flows from the same device, and building batching for efficient training/inference. I developed and compared both 3-layer and 4-layer GraphSAGE architectures, tuned hyperparameters, and ran training/evaluation on GPU. To address severe class imbalance, I implemented class-weighted loss along with early stopping and learning-rate scheduling. I generated the full evaluation suite for the GNN approach (confusion matrices, precision/recall plots, and per-class metrics), wrote the GNN methods/results sections, integrated findings into the final report, and produced the final poster.
